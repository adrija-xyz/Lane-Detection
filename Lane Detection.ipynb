{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d151af-5026-4146-8ffe-2def330aa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02a083-2a39-4fdc-aefc-b59a43fce0cb",
   "metadata": {},
   "source": [
    "## Preprocessing of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72383e24-dbf0-4b0c-a1df-6a829b2d58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    #Denoising the Image - Median Filter\n",
    "    denoised_image = cv2.medianBlur(image, 5)\n",
    "    \n",
    "    #Blurring the Image - Gaussian Filter\n",
    "    blurred_image = cv2.GaussianBlur(denoised_image, (5, 5), 0)\n",
    "\n",
    "    #Applying colour space transformation\n",
    "    hls_image=cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    hue=hls_image[:,:,0]\n",
    "    lightness=hls_image[:,:,1]\n",
    "    saturation=hls_image[:,:,2]\n",
    "\n",
    "    #Calculating Sobel Gradient along x-axis on Lightness Channel\n",
    "    sobelx = cv2.Sobel(lightness,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobelx_abs=np.abs(sobelx)\n",
    "    #Scaling the gradient values\n",
    "    sobelx_scaled=((sobelx_abs/np.max(sobelx_abs))*255).astype(np.uint8)\n",
    "\n",
    "    #Thresholding gradient values on Lightness Channel\n",
    "    sobelx_threshold=np.copy(sobelx_scaled)\n",
    "    sobelx_threshold[(sobelx_scaled >= 50) & (sobelx_scaled<=255)]=1\n",
    "    sobelx_threshold[sobelx_scaled < 50]=0\n",
    "\n",
    "    #Thresholding Saturation Channel\n",
    "    saturation_threshold=np.copy(saturation)\n",
    "    saturation[(sobelx_scaled >= 150) & (sobelx_scaled<=255)]=1\n",
    "    saturation[sobelx_scaled < 150]=0\n",
    "\n",
    "    #Combining the Results\n",
    "    combined_image=np.zeros(sobelx_threshold.shape)\n",
    "    combined_image[((sobelx_threshold == 1) | (saturation_threshold == 1))]=1\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130ecc3-eb67-4452-afe5-80e83818cd35",
   "metadata": {},
   "source": [
    "## Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b363e69-fa01-4085-8c8d-abb8ae0e34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(image):\n",
    "    triangle_height=image.shape[0]\n",
    "    roi_vertices = np.array([[(250, triangle_height), (1170, triangle_height), (600, 370)]], dtype=np.int32)\n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, roi_vertices, 255)\n",
    "    masked_image=cv2.bitwise_and(image,mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a38fe1-b5e8-4124-85b1-7f8dd784f43b",
   "metadata": {},
   "source": [
    "## Finding Equations of Left and Right Lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e1a816-7f86-4f23-843c-76355b70cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_lines_by_slope(lines):\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1) if x2 != x1 else 0\n",
    "            if slope < 0:\n",
    "                left_lines.append((slope, x1, y1, x2, y2))\n",
    "            else:\n",
    "                right_lines.append((slope, x1, y1, x2, y2))\n",
    "    \n",
    "    return left_lines, right_lines\n",
    "\n",
    "def average_lines(lines):\n",
    "    if len(lines) == 0:\n",
    "        return None\n",
    "    slopes = [line[0] for line in lines]\n",
    "    x1 = np.mean([line[1] for line in lines])\n",
    "    y1 = np.mean([line[2] for line in lines])\n",
    "    x2 = np.mean([line[3] for line in lines])\n",
    "    y2 = np.mean([line[4] for line in lines])\n",
    "\n",
    "    return x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840244f4-4bfc-4df6-97c2-e32e44c9ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolate_line_green(x1, y1, x2, y2, y_limit=200):\n",
    "    slope = (y2 - y1) / (x2 - x1) if x2 != x1 else 0\n",
    "    intercept = y1 - slope * x1\n",
    "\n",
    "    y_bottom = y_limit\n",
    "    x_bottom = int((y_bottom - intercept) / slope) if slope != 0 else int(x1)\n",
    "\n",
    "    x_modified=(720-intercept)/slope\n",
    "\n",
    "    return (x_modified, 720, x_bottom, y_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2625a2e4-0430-4a22-9f2c-a002bac772c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolate_line_red(x1, y1, x2, y2, y_limit=200):\n",
    "    slope = (y2 - y1) / (x2 - x1) if x2 != x1 else 0\n",
    "    intercept = y1 - slope * x1\n",
    "\n",
    "    y_bottom = y_limit\n",
    "    x_bottom = int((y_bottom - intercept) / slope) if slope != 0 else int(x1)\n",
    "\n",
    "    x_modified=(500-intercept)/slope\n",
    "\n",
    "    return (x_modified, 500, x_bottom, y_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c68edf2-7c29-411c-ac50-a5cea6e3ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lines(image, left_lines, right_lines, y_limit):\n",
    "    line_image = np.zeros_like(image)\n",
    "\n",
    "    if left_lines:\n",
    "        x1, y1, x2, y2 = average_lines(left_lines)\n",
    "        if x1 is not None:\n",
    "            x1, y1, x2, y2 = extrapolate_line_green(x1, y1, x2, y2, y_limit)\n",
    "            cv2.line(line_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 10)\n",
    "\n",
    "    if right_lines:\n",
    "        x1, y1, x2, y2 = average_lines(right_lines)\n",
    "        if x1 is not None:\n",
    "            x1, y1, x2, y2 = extrapolate_line_red(x1, y1, x2, y2, 720)\n",
    "            cv2.line(line_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 10)\n",
    "\n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fea605-972a-4b2c-b82b-f132177f76e7",
   "metadata": {},
   "source": [
    "## Lane Detection in Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1082296-db7d-4b62-87cb-fea1ab438430",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'input_video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    processed_image = process_image(frame)\n",
    "    processed_image = (processed_image * 255).astype(np.uint8)\n",
    "    \n",
    "    edges = region_of_interest(processed_image)\n",
    "    lines = cv2.HoughLinesP(edges, 2, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=50)\n",
    "    if lines is not None:\n",
    "        left_lines, right_lines = classify_lines_by_slope(lines)\n",
    "        line_image = display_lines(frame, left_lines, right_lines, y_limit=500)\n",
    "        combo_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)\n",
    "        cv2.imshow('Lane Detection', combo_image)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
